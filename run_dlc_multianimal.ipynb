{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["txoddlM8hLKm","F3UozmkGLpVp"],"provenance":[{"file_id":"1HsFGRdJ2D2eM6kxs_nXBswqPiyK2J_FT","timestamp":1662484136220}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"txoddlM8hLKm"},"source":["## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n","- remember to restart runtime after installing deeplabcut\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"metadata":{"id":"DjSl7RH6WMJB","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1688428466696,"user_tz":240,"elapsed":7488,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"b32fe7e3-6273-47b4-ac3e-f167d3c2c06d"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"q23BzhA6CXxu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1688428612250,"user_tz":240,"elapsed":145559,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"1f526f18-0367-4570-afe3-58491345ee22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting deeplabcut[tf]\n","  Downloading deeplabcut-2.3.5-py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dlclibrary (from deeplabcut[tf])\n","  Downloading dlclibrary-0.0.3-py3-none-any.whl (14 kB)\n","Collecting filterpy>=1.4.4 (from deeplabcut[tf])\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ruamel.yaml>=0.15.0 (from deeplabcut[tf])\n","  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (0.4.0)\n","Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (0.4.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (0.56.4)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (3.7.1)\n","Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (3.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (1.22.4)\n","Requirement already satisfied: pandas!=1.5.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (1.5.3)\n","Requirement already satisfied: scikit-image>=0.17 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (0.19.3)\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (1.2.2)\n","Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (1.10.1)\n","Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (0.13.5)\n","Requirement already satisfied: tables>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (3.8.0)\n","Collecting torch<=1.12 (from deeplabcut[tf])\n","  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorpack>=0.11 (from deeplabcut[tf])\n","  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (4.65.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (6.0)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from deeplabcut[tf]) (8.4.0)\n","Collecting tensorflow<=2.10,>=2.0 (from deeplabcut[tf])\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut[tf]) (1.16.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut[tf]) (4.7.0.72)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut[tf]) (2.25.1)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->deeplabcut[tf]) (2.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->deeplabcut[tf]) (2.8.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut[tf]) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->deeplabcut[tf]) (67.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,>=1.0.1->deeplabcut[tf]) (2022.7.1)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.15.0->deeplabcut[tf])\n","  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut[tf]) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17->deeplabcut[tf]) (1.4.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut[tf]) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->deeplabcut[tf]) (3.1.0)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->deeplabcut[tf]) (0.5.3)\n","Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut[tf]) (0.29.35)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut[tf]) (2.8.4)\n","Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut[tf]) (2.0.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables>=3.7.0->deeplabcut[tf]) (9.0.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.56.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (3.8.0)\n","Collecting keras<2.11,>=2.10.0 (from tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (16.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (3.3.0)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.11,>=2.10 (from tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.32.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (4.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.14.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut[tf]) (0.8.10)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut[tf]) (1.0.5)\n","Collecting msgpack-numpy>=0.4.4.2 (from tensorpack>=0.11->deeplabcut[tf])\n","  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut[tf]) (23.2.1)\n","Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from tensorpack>=0.11->deeplabcut[tf]) (5.9.5)\n","Collecting huggingface-hub (from dlclibrary->deeplabcut[tf])\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.27.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf])\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.3.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut[tf]) (3.12.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->dlclibrary->deeplabcut[tf]) (2023.6.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<=2.10,>=2.0->deeplabcut[tf]) (3.2.2)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=15273b8fe1d1bad5bde92c5910e0087243360b1570a5dfb606b009428c7c10ef\n","  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n","Successfully built filterpy\n","Installing collected packages: tensorboard-plugin-wit, keras, torch, tensorflow-estimator, tensorboard-data-server, ruamel.yaml.clib, protobuf, msgpack-numpy, keras-preprocessing, tensorpack, ruamel.yaml, huggingface-hub, google-auth-oauthlib, filterpy, dlclibrary, tensorboard, deeplabcut, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.1\n","    Uninstalling tensorboard-data-server-0.7.1:\n","      Successfully uninstalled tensorboard-data-server-0.7.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.3\n","    Uninstalling tensorboard-2.12.3:\n","      Successfully uninstalled tensorboard-2.12.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed deeplabcut-2.3.5 dlclibrary-0.0.3 filterpy-1.4.5 google-auth-oauthlib-0.4.6 huggingface-hub-0.15.1 keras-2.10.0 keras-preprocessing-1.1.2 msgpack-numpy-0.4.8 protobuf-3.19.6 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorpack-0.11 torch-1.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","keras","tensorboard","tensorflow"]}}},"metadata":{}}],"source":["#(this will take a few minutes to install all the dependences!)\n","!pip install 'deeplabcut[tf]'\n","%reload_ext numpy\n","%reload_ext scipy\n","%reload_ext matplotlib\n","%reload_ext mpl_toolkits"]},{"cell_type":"markdown","source":["# need to restart runtime again after these packages"],"metadata":{"id":"mU4HJDlBUi2W"}},{"cell_type":"code","metadata":{"id":"-MVvZ13_FMvP","colab":{"base_uri":"https://localhost:8080/","height":939},"executionInfo":{"status":"ok","timestamp":1688429264416,"user_tz":240,"elapsed":18112,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"4499e38b-bdad-44fd-e17d-7c3bdd5b8f4f"},"source":["#a few colab specific things needed:\n","!pip install --upgrade scikit-image\n","!pip3 install pickle5"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n","Collecting scikit-image\n","  Downloading scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.22.4)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n","Collecting pillow>=9.0.1 (from scikit-image)\n","  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting imageio>=2.27 (from scikit-image)\n","  Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n","Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.2)\n","Installing collected packages: pillow, imageio, scikit-image\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 8.4.0\n","    Uninstalling Pillow-8.4.0:\n","      Successfully uninstalled Pillow-8.4.0\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.25.1\n","    Uninstalling imageio-2.25.1:\n","      Successfully uninstalled imageio-2.25.1\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed imageio-2.31.1 pillow-10.0.0 scikit-image-0.21.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting pickle5\n","  Downloading pickle5-0.0.11.tar.gz (132 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pickle5\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=256411 sha256=0aa03abc5973f80bb318e026a8fc840b7e2e23929f209c1a19e4db5e7f46b9b0\n","  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n","Successfully built pickle5\n","Installing collected packages: pickle5\n","Successfully installed pickle5-0.0.11\n"]}]},{"cell_type":"markdown","source":["#install other packages and setup\n","- connect to google drive in this step"],"metadata":{"id":"F3UozmkGLpVp"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"oTwAcbq2-FZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688429291764,"user_tz":240,"elapsed":11848,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"958ee832-a45d-4283-d0b2-7fd0b01ee3ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading DLC 2.3.5...\n","DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"]}],"source":["import os\n","import deeplabcut\n","import numpy as np\n","import pandas as pd\n","import pickle5 as pickle\n","from deeplabcut.utils import auxfun_multianimal, auxiliaryfunctions\n","import random\n","from pathlib import Path\n","import glob"]},{"cell_type":"markdown","source":["DLC 2.3.5 is ok"],"metadata":{"id":"IJWFDxMeUuBP"}},{"cell_type":"markdown","metadata":{"id":"cQ-nlTkri4HZ"},"source":["Link your Google Drive (with your labeled data):"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KS4Q4UkR9rgG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688429311270,"user_tz":240,"elapsed":19509,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"6c535cc5-96d4-4b33-bcdc-00e5baa68f5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["#Now, let's link to your Google Drive. Run this cell and follow the authorization instructions:\n","#(We recommend putting a copy of the github repo in your google drive if you are using the demo \"examples\")\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["# # Download our demo project:\n","# import urllib.request\n","# from io import BytesIO\n","# from zipfile import ZipFile\n","#\n","# def unzip_from_url(url, dest_folder='/'):\n","#    # Directly extract files without writing the archive to disk\n","#    resp = urllib.request.urlopen(url)\n","#    with ZipFile(BytesIO(resp.read())) as zf:\n","#       zf.extractall(path=dest_folder)\n","\n","# project_url = \"http://deeplabcut.rowland.harvard.edu/datasets/demo-me-2021-07-14.zip\"\n","# unzip_from_url(project_url, \"/content/drive/MyDrive/\")"],"metadata":{"id":"GPcbjcmw9JT0","executionInfo":{"status":"ok","timestamp":1688429311271,"user_tz":240,"elapsed":5,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["project_path = \"/content/drive/MyDrive/230702/demo-me-2021-07-14\"\n","config_path = os.path.join(project_path, \"config.yaml\")\n","tracklets_config_path = os.path.join(project_path, \"tracklets_config.yaml\")"],"metadata":{"id":"NY3F2BtH9j-n","executionInfo":{"status":"ok","timestamp":1688429311271,"user_tz":240,"elapsed":4,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["SHUFFLE=1\n","TRACK_METHOD = \"ellipse\"  # Could also be \"box\", but \"ellipse\" was found to be more robust on this dataset."],"metadata":{"id":"fePUgz1i9sxX","executionInfo":{"status":"ok","timestamp":1688429311271,"user_tz":240,"elapsed":3,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip show deeplabcut"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtQxOWk_w-OT","executionInfo":{"status":"ok","timestamp":1688429315967,"user_tz":240,"elapsed":4699,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"outputId":"50b2e0cc-5023-4977-ff11-162a75ac24c4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: deeplabcut\n","Version: 2.3.5\n","Summary: Markerless pose-estimation of user-defined features with deep learning\n","Home-page: https://github.com/DeepLabCut/DeepLabCut\n","Author: A. & M. Mathis Labs\n","Author-email: alexander@deeplabcut.org\n","License: \n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: dlclibrary, filterpy, imageio-ffmpeg, imgaug, matplotlib, networkx, numba, numpy, pandas, Pillow, pyyaml, ruamel.yaml, scikit-image, scikit-learn, scipy, statsmodels, tables, tensorpack, tf-slim, torch, tqdm\n","Required-by: \n"]}]},{"cell_type":"markdown","source":["# _running analysis for all right now_"],"metadata":{"id":"q9AiukAcAwGQ"}},{"cell_type":"markdown","source":["#Analyze all videos in \"videos\" folder:"],"metadata":{"id":"8s6YzRXKAnWl"}},{"cell_type":"code","source":["#running for all right now\n","for video in [project_path + \"/videos/221127_PZ89_1.avi\"]:\n","#for video in glob.glob(project_path + \"/videos/\" + \"*.avi\"):\n","  print(video)\n","  deeplabcut.analyze_videos(config_path,[video], shuffle=SHUFFLE, videotype=\"avi\",auto_track=False, use_shelve=False)\n","  #deeplabcut.convert_detections2tracklets(\n","  #    config_path,\n","  #    [video],\n","  #    videotype='avi',\n","  #    shuffle=0,\n","  #    track_method=TRACK_METHOD,\n","  #    ignore_bodyparts=[\"tail1\", \"tail2\", \"tailend\"],  # Some body parts can optionally be ignored during tracking for better assembly (but they are used later)\n","  #)\n","  #deeplabcut.stitch_tracklets(\n","  #  config_path,\n","  #  [video],\n","  #  videotype='avi',\n","  #  shuffle=0,\n","  #  track_method=TRACK_METHOD,\n","  #  n_tracks=3,\n","  #)\n","\n","  #Filter the predictions to remove small jitter, if desired:\n","  #deeplabcut.filterpredictions(config_path,\n","  #                              [video],\n","  #                              shuffle=0,\n","  #                              videotype='avi',\n","  #                              track_method = TRACK_METHOD)\n","  #deeplabcut.create_labeled_video(\n","  #  config_path,\n","  #  [video],\n","  #  videotype='avi',\n","  #  shuffle=0,\n","  #  color_by=\"individual\",\n","  #  keypoints_only=False,\n","  #  draw_skeleton=True,\n","  #  filtered=True,\n","  #  track_method=TRACK_METHOD,\n","  #)"],"metadata":{"id":"tDk2ypeTAlc9","executionInfo":{"status":"ok","timestamp":1688429448567,"user_tz":240,"elapsed":129083,"user":{"displayName":"Paula Zhu","userId":"01740114582831200249"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b389c1d-6948-46ee-c270-4d2b1d145b67"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/230702/demo-me-2021-07-14/videos/221127_PZ89_1.avi\n","Using snapshot-50000 for model /content/drive/MyDrive/230702/demo-me-2021-07-14/dlc-models/iteration-2/demoJul14-trainset95shuffle1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Activating extracting of PAFs\n","Starting to analyze %  /content/drive/MyDrive/230702/demo-me-2021-07-14/videos/221127_PZ89_1.avi\n","Loading  /content/drive/MyDrive/230702/demo-me-2021-07-14/videos/221127_PZ89_1.avi\n","Duration of video [s]:  356.47 , recorded with  30.0 fps!\n","Overall # of frames:  10694  found with (before cropping) frame dimensions:  292 173\n","Starting to extract posture from the video(s) with batchsize: 8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10694/10694 [01:37<00:00, 110.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Video Analyzed. Saving results in /content/drive/MyDrive/230702/demo-me-2021-07-14/videos...\n","The videos are analyzed. Time to assemble animals and track 'em... \n"," Call 'create_video_with_all_detections' to check multi-animal detection quality before tracking.\n","If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"]}]}]}